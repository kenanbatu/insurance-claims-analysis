[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Project Details",
    "section": "",
    "text": "Insurance companies need to understand which policies are more likely to result in claims so they can price risk appropriately and focus attention on higher-risk customers. However, in our dataset only about 6.4% of policies have a claim, while 93.6% do not. This strong class imbalance (about 14.6 : 1) makes prediction challenging, because a naïve model could achieve high accuracy by always predicting “no claim” without learning any useful pattern."
  },
  {
    "objectID": "about.html#the-problem",
    "href": "about.html#the-problem",
    "title": "Project Details",
    "section": "",
    "text": "Insurance companies need to understand which policies are more likely to result in claims so they can price risk appropriately and focus attention on higher-risk customers. However, in our dataset only about 6.4% of policies have a claim, while 93.6% do not. This strong class imbalance (about 14.6 : 1) makes prediction challenging, because a naïve model could achieve high accuracy by always predicting “no claim” without learning any useful pattern."
  },
  {
    "objectID": "about.html#the-data",
    "href": "about.html#the-data",
    "title": "Project Details",
    "section": "The Data",
    "text": "The Data\nWe work with a dataset of 58,592 insurance policies and 41 features, including:\n\nPolicy information (subscription length, policy details)\nVehicle characteristics (vehicle age, engine specs, safety features)\nRegional information (region codes and region density)\nA binary target variable claim_status indicating whether a claim occurred (1) or not (0)\n\nDuring our initial checks, we confirmed:\n\nNo missing values\n\nNo duplicate rows\n\nConsistent data types across columns\n\nThis allowed us to focus on feature engineering and modeling instead of heavy data cleaning."
  },
  {
    "objectID": "about.html#our-approach",
    "href": "about.html#our-approach",
    "title": "Project Details",
    "section": "Our Approach",
    "text": "Our Approach\nOur main steps were:\n\nData validation and preparation\n\nVerified there were no missing values or duplicates\n\nEncoded categorical variables into numeric form suitable for modeling\n\nCreated simple engineered features (e.g., grouping ages or combining risk-related information)\n\nExploratory data analysis (EDA)\n\nMeasured class imbalance (93.6% no-claim vs 6.4% claim)\n\nExamined distributions of key features such as subscription length and vehicle age\n\nCompared claim rates across regions and other relevant categories\n\nHandling class imbalance\n\nApplied Random Oversampling to the training set only, so the model could learn from enough claim examples while still evaluating on the original, imbalanced test set.\n\nModeling and evaluation\n\nTrained a Random Forest classifier on the oversampled training data\n\nEvaluated the model on the untouched test data using:\n\nAccuracy\nPrecision\nRecall\nF1-score\nROC-AUC\nConfusion matrix"
  },
  {
    "objectID": "about.html#high-level-findings",
    "href": "about.html#high-level-findings",
    "title": "Project Details",
    "section": "High-Level Findings",
    "text": "High-Level Findings\n\nThe target variable is heavily imbalanced, but oversampling helps the model recognize claim cases.\nFeatures like subscription length, vehicle age, and region-related variables are among the most important predictors in the Random Forest model.\nThe model is able to capture non-random patterns in claim behavior and can serve as a screening tool to flag higher-risk policies for closer review."
  },
  {
    "objectID": "about.html#team",
    "href": "about.html#team",
    "title": "Project Details",
    "section": "Team",
    "text": "Team\n\nKenan Batu\nNyasha Sibanda"
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "Model & Results",
    "section": "",
    "text": "The target variable (claim_status) is highly imbalanced:\n\n93.6% of policies result in no claim\n6.4% of policies result in a claim\nImbalance ratio: 14.6 : 1\n\nA model trained directly on this distribution would tend to predict “no claim” almost every time. To address this, we:\n\nSplit the data into training and test sets (80/20).\nApplied Random Oversampling to the training set only, balancing the classes.\nLeft the test set untouched to reflect real-world conditions.\n\nTraining set before oversampling:\n\nNo claim: 43,875\n\nClaim: 2,998\n\nTraining set after oversampling:\n\nNo claim: 43,875\n\nClaim: 43,875\n\nThis ensures the model sees enough claim examples to learn meaningful patterns."
  },
  {
    "objectID": "model.html#handling-class-imbalance",
    "href": "model.html#handling-class-imbalance",
    "title": "Model & Results",
    "section": "",
    "text": "The target variable (claim_status) is highly imbalanced:\n\n93.6% of policies result in no claim\n6.4% of policies result in a claim\nImbalance ratio: 14.6 : 1\n\nA model trained directly on this distribution would tend to predict “no claim” almost every time. To address this, we:\n\nSplit the data into training and test sets (80/20).\nApplied Random Oversampling to the training set only, balancing the classes.\nLeft the test set untouched to reflect real-world conditions.\n\nTraining set before oversampling:\n\nNo claim: 43,875\n\nClaim: 2,998\n\nTraining set after oversampling:\n\nNo claim: 43,875\n\nClaim: 43,875\n\nThis ensures the model sees enough claim examples to learn meaningful patterns."
  },
  {
    "objectID": "model.html#model-random-forest-classifier",
    "href": "model.html#model-random-forest-classifier",
    "title": "Model & Results",
    "section": "Model: Random Forest Classifier",
    "text": "Model: Random Forest Classifier\nWe trained a Random Forest classifier, which is well-suited for this problem because it:\n\nHandles mixed numerical and encoded categorical features\n\nCaptures nonlinear relationships and interactions\n\nProvides feature importance to help interpret the model\n\nKey hyperparameters:\n\nn_estimators: 100\n\nmax_depth: 10\n\nmin_samples_split: 20\n\nmin_samples_leaf: 10\n\nclass_weight: “balanced”\n\nrandom_state: 42\n\nThe model was trained on the oversampled training data and evaluated on the original test set."
  },
  {
    "objectID": "model.html#performance-on-test-data",
    "href": "model.html#performance-on-test-data",
    "title": "Model & Results",
    "section": "Performance on Test Data",
    "text": "Performance on Test Data\nFinal Random Forest results:\n\nAccuracy: 63.4%\n\nPrecision: 10.1%\n\nRecall: 59.3%\n\nF1-score: 0.17\n\nROC-AUC: 0.66\n\n\nInterpretation\n\nThe model correctly identifies many actual claim cases (good recall), which is important in an insurance context where missing a claim can be costly.\nPrecision is relatively low, meaning many flagged policies do not end up having a claim. This is a trade-off: the model is more conservative and prefers to over-flag potential risks.\nAn ROC-AUC of about 0.66 indicates moderate ability to distinguish claim vs. no-claim policies, clearly better than random guessing."
  },
  {
    "objectID": "model.html#combined-model-visualization",
    "href": "model.html#combined-model-visualization",
    "title": "Model & Results",
    "section": "Combined Model Visualization",
    "text": "Combined Model Visualization\nThe figure below summarizes the main evaluation visuals from the model:\n\nConfusion Matrix\n\nROC Curve\n\nPrecision–Recall Curve\n\nFeature Importance (Top Predictors)\n\nPresenting these together provides a compact overview of model behavior and performance."
  },
  {
    "objectID": "model.html#feature-interpretation",
    "href": "model.html#feature-interpretation",
    "title": "Model & Results",
    "section": "Feature Interpretation",
    "text": "Feature Interpretation\nBased on the Random Forest feature importance scores, the most influential predictors include:\n\nSubscription length\n\nVehicle age\n\nRisk-related engineered features\n\nCustomer age\n\nRegion encodings and density measures\n\nThese results are consistent with our exploratory analysis:\n\nOlder vehicles are more likely to be involved in claims.\n\nLonger subscription histories reflect more exposure time and accumulated risk.\n\nSome regions and population densities are associated with higher claim frequencies.\n\nTogether, these variables help the model prioritize which policies are more likely to result in claims."
  },
  {
    "objectID": "model.html#business-interpretation",
    "href": "model.html#business-interpretation",
    "title": "Model & Results",
    "section": "Business Interpretation",
    "text": "Business Interpretation\nFrom an insurance perspective, the model can be used as a screening tool to:\n\nFlag higher-risk policies for manual underwriting review\n\nSupport region-based pricing or adjustment of risk tiers\n\nIncorporate vehicle age, subscription behavior, and regional risk into decision-making\n\nEven though the model does not achieve perfect precision, its relatively high recall and reasonable ROC-AUC make it useful for focusing attention where the risk of claims is elevated, rather than replacing human judgment entirely."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Insurance Claims Analysis",
    "section": "",
    "text": "This website summarizes our group project on predicting the likelihood that an insurance policy will result in a claim. The dataset contains information about policyholders, their vehicles, and their regions, along with a binary target variable indicating whether a claim occurred.\nBecause claims are rare compared to non-claims (only about 6.4% of policies result in a claim), the data is highly imbalanced. This makes simple accuracy misleading and motivates the need for careful modeling.\nWe clean and validate the data, explore key patterns, address the class imbalance using Random Oversampling, and train a Random Forest classification model to estimate claim risk."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Insurance Claims Analysis",
    "section": "",
    "text": "This website summarizes our group project on predicting the likelihood that an insurance policy will result in a claim. The dataset contains information about policyholders, their vehicles, and their regions, along with a binary target variable indicating whether a claim occurred.\nBecause claims are rare compared to non-claims (only about 6.4% of policies result in a claim), the data is highly imbalanced. This makes simple accuracy misleading and motivates the need for careful modeling.\nWe clean and validate the data, explore key patterns, address the class imbalance using Random Oversampling, and train a Random Forest classification model to estimate claim risk."
  },
  {
    "objectID": "index.html#what-youll-find-here",
    "href": "index.html#what-youll-find-here",
    "title": "Insurance Claims Analysis",
    "section": "What You’ll Find Here",
    "text": "What You’ll Find Here\n\nA description of the problem and dataset\nA summary of our data cleaning and validation steps\nKey visualizations illustrating class imbalance and feature patterns\nModel performance results (accuracy, recall, ROC-AUC, and more)\nBusiness insights on how these results could support insurance decision-making"
  },
  {
    "objectID": "index.html#final-model-snapshot",
    "href": "index.html#final-model-snapshot",
    "title": "Insurance Claims Analysis",
    "section": "Final Model Snapshot",
    "text": "Final Model Snapshot\nOur final Random Forest model, trained on oversampled data and evaluated on the original test set, achieves:\n\nAccuracy: 63.4%\n\nRecall: 59.3%\n\nROC-AUC: 0.66\n\nThese results show that the model can identify a majority of true claims while working with a challenging, highly imbalanced dataset."
  }
]